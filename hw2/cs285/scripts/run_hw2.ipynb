{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "home = os.path.expanduser('~')\n",
    "ex_path = home + '/Documents/Python/BerkeleyDRL_fall2021/hw2'\n",
    "os.chdir(ex_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "-p6i5TqAhW4a"
   },
   "outputs": [],
   "source": [
    "## cythonize at the first import\n",
    "import mujoco_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "noinfUbHiHW2"
   },
   "outputs": [],
   "source": [
    "#@title set up virtual display\n",
    "\n",
    "from pyvirtualdisplay import Display\n",
    "#os.environ['DISPLAY'] = ':0'\n",
    "if '/usr/X11/bin:' not in os.environ['PATH']: os.environ['PATH'] = '/usr/X11/bin:' + os.environ['PATH']\n",
    "display = Display(visible=0, size=(1400, 900))\n",
    "display.start();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 438
    },
    "colab_type": "code",
    "id": "COqsZLeliU9Y",
    "outputId": "55f7feb0-e730-4789-c73d-3ec695b48757",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title test virtual display\n",
    "\n",
    "#@markdown If you see a video of a four-legged ant fumbling about, setup is complete!\n",
    "\n",
    "import gym\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from cs285.infrastructure.colab_utils import (\n",
    "    wrap_env,\n",
    "    show_video\n",
    ")\n",
    "  \n",
    "env = wrap_env(gym.make(\"Ant-v2\"))#(\"MsPacman-v0\", render_mode='human'))\n",
    "\n",
    "observation = env.reset()\n",
    "for i in range(100):\n",
    "    env.render(mode='rgb_array')\n",
    "    obs, rew, term, _ = env.step(env.action_space.sample() ) \n",
    "    if term:\n",
    "        break;\n",
    "\n",
    "env.close()\n",
    "print('Loading video...')\n",
    "show_video()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9qUmV93fif6S"
   },
   "source": [
    "## Run Policy Gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "lN-gZkqiijnR",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title imports\n",
    "\n",
    "import os\n",
    "import time\n",
    "\n",
    "from cs285.infrastructure.rl_trainer import RL_Trainer\n",
    "from cs285.agents.pg_agent import PGAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab": {},
    "colab_type": "code",
    "id": "Q6NaOWhOinnU"
   },
   "outputs": [],
   "source": [
    "#@title runtime arguments\n",
    "\n",
    "class Args:\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return getattr(self, key)\n",
    "\n",
    "    def __setitem__(self, key, val):\n",
    "        setattr(self, key, val)\n",
    "\n",
    "    def __contains__(self, key):\n",
    "        return hasattr(self, key)\n",
    "\n",
    "    env_name = 'CartPole-v0' #@param\n",
    "    exp_name = 'q1_sb_rtg_na' #@param\n",
    "\n",
    "    #@markdown main parameters of interest\n",
    "    n_iter = 50 #@param {type: \"integer\"}\n",
    "\n",
    "    ## PDF will tell you how to set ep_len\n",
    "    ## and discount for each environment\n",
    "    ep_len = 200 #@param {type: \"integer\"}\n",
    "    discount = 0.95 #@param {type: \"number\"}\n",
    "\n",
    "    reward_to_go = True #@param {type: \"boolean\"}\n",
    "    nn_baseline = True #@param {type: \"boolean\"}\n",
    "    gae_lambda = None #@param {type: \"number\"}\n",
    "    dont_standardize_advantages = False #@param {type: \"boolean\"}\n",
    "\n",
    "    #@markdown batches and steps\n",
    "    batch_size = 1000 #@param {type: \"integer\"}\n",
    "    eval_batch_size = 400 #@param {type: \"integer\"}\n",
    "\n",
    "    num_agent_train_steps_per_iter = 1 #@param {type: \"integer\"}\n",
    "    learning_rate =  5e-3 #@param {type: \"number\"}\n",
    "\n",
    "    #@markdown MLP parameters\n",
    "    n_layers = 2 #@param {type: \"integer\"}\n",
    "    size = 64 #@param {type: \"integer\"}\n",
    "\n",
    "    #@markdown system\n",
    "    save_params = False #@param {type: \"boolean\"}\n",
    "    no_gpu = True #@param {type: \"boolean\"}\n",
    "    which_gpu = 0 #@param {type: \"integer\"}\n",
    "    seed = 1 #@param {type: \"integer\"}\n",
    "\n",
    "    action_noise_std = 0 #@param {type: \"number\"}\n",
    "\n",
    "    #@markdown logging\n",
    "    ## default is to not log video so\n",
    "    ## that logs are small enough to be\n",
    "    ## uploaded to gradscope\n",
    "    video_log_freq =  -1#@param {type: \"integer\"}\n",
    "    scalar_log_freq =  1#@param {type: \"integer\"}\n",
    "\n",
    "\n",
    "args = Args()\n",
    "\n",
    "## ensure compatibility with hw1 code\n",
    "args['train_batch_size'] = args['batch_size']\n",
    "\n",
    "if args['video_log_freq'] > 0:\n",
    "    import warnings\n",
    "    warnings.warn(\n",
    "      '''\\nLogging videos will make eventfiles too'''\n",
    "      '''\\nlarge for the autograder. Set video_log_freq = -1'''\n",
    "      '''\\nfor the runs you intend to submit.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "eScWwHhnsYkd"
   },
   "outputs": [],
   "source": [
    "#@title create directory for logging\n",
    "\n",
    "data_path = ex_path + '/data'\n",
    "\n",
    "if not (os.path.exists(data_path)):\n",
    "    os.makedirs(data_path)\n",
    "\n",
    "logdir = args.exp_name + '_' + args.env_name + '_' + time.strftime(\"%d-%m-%Y_%H-%M-%S\")\n",
    "logdir = os.path.join(data_path, logdir)\n",
    "args['logdir'] = logdir\n",
    "if not(os.path.exists(logdir)):\n",
    "    os.makedirs(logdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aljzrLdAsvNu"
   },
   "outputs": [],
   "source": [
    "## define policy gradient trainer\n",
    "\n",
    "class PG_Trainer(object):\n",
    "\n",
    "    def __init__(self, params):\n",
    "\n",
    "        #####################\n",
    "        ## SET AGENT PARAMS\n",
    "        #####################\n",
    "\n",
    "        computation_graph_args = {\n",
    "            'n_layers': params['n_layers'],\n",
    "            'size': params['size'],\n",
    "            'learning_rate': params['learning_rate'],\n",
    "            }\n",
    "\n",
    "        estimate_advantage_args = {\n",
    "            'gamma': params['discount'],\n",
    "            'standardize_advantages': not(params['dont_standardize_advantages']),\n",
    "            'reward_to_go': params['reward_to_go'],\n",
    "            'nn_baseline': params['nn_baseline'],\n",
    "            'gae_lambda': params['gae_lambda'],\n",
    "        }\n",
    "\n",
    "        train_args = {\n",
    "            'num_agent_train_steps_per_iter': params['num_agent_train_steps_per_iter'],\n",
    "        }\n",
    "\n",
    "        agent_params = {**computation_graph_args, **estimate_advantage_args, **train_args}\n",
    "\n",
    "        self.params = params\n",
    "        self.params['agent_class'] = PGAgent\n",
    "        self.params['agent_params'] = agent_params\n",
    "        self.params['batch_size_initial'] = self.params['batch_size']\n",
    "\n",
    "        ################\n",
    "        ## RL TRAINER\n",
    "        ################\n",
    "\n",
    "        self.rl_trainer = RL_Trainer(self.params)\n",
    "\n",
    "    def run_training_loop(self):\n",
    "\n",
    "        self.rl_trainer.run_training_loop(\n",
    "            self.params['n_iter'],\n",
    "            collect_policy = self.rl_trainer.agent.actor,\n",
    "            eval_policy = self.rl_trainer.agent.actor,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j2rCuQsRsd3N",
    "tags": []
   },
   "outputs": [],
   "source": [
    "## run training\n",
    "\n",
    "print(args.logdir)\n",
    "trainer = PG_Trainer(args)\n",
    "trainer.run_training_loop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "km7LlYvhqKTl"
   },
   "outputs": [],
   "source": [
    "#@markdown You can visualize your runs with tensorboard from within the notebook\n",
    "\n",
    "## requires tensorflow==2.3.0\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /Users/ikasou/Documents/Python/BerkeleyDRL_fall2021/hw2/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(3, 5, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.randint(5, (3,), dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = torch.randn(3, 1).softmax(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "run_hw2.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
